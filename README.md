# Human Visual Attention [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
This repository contains a curated list of research papers and resources focusing on saliency and scanpath prediction, human attention, human visual search.


‚ùó Latest Update: 22 November 2023. Work in progress, new updates coming soon !!! :construction: :construction:

## üìö Table of Contents
- [Human Attention Modelling](#human-attention-modelling)
    - [Saliency Prediction](#saliency-prediction)
    - [Scanpath Prediction](#scanpath-prediction)
- [Integrating Human Attention in AI models](#integrating-human-attention-in-ai-models)
    - [Image and Video Processing](#image-and-videoprocessing)
        - [Visual Recognition](#visual-recognition)
        - [Graphic Design](#graphic-design)
        - [Image Enhancement and Manipulation](#image-enhancement-and-manipulation)
        - [Image Quality Assessment](#image-quality-assessment)
    - [Vision-and-Language Applications](#vision-and-language)
        - [Automatic Captioning](#automatic-captioning)
        - [Visual Question Answering](#visual-question-answering)
    - [Language Modelling](#language-modelling)
        - [Machine Reading Comprehension](#machine-reading-comprehension)
        - [Natural Language Understanding](#natural-language-understanding)
    - [Domain-Specific Applications](#domain-specific-applications)
        - [Robotics](#robotics)
        - [Autonomous Driving](#autonomous-driving)
        - [Medicine](#medicine)

# Human Attention Modelling
## Saliency Prediction
| **Year** | **Conference / Journal** | **Title** | **Authors** | **Links** |
|:--------:|:--------------:|:----------------------------------------------------|:---------------------|:---------:|
|   2023   |      CVPR      | Learning from Unique Perspectives: User-aware Saliency Modeling | *Shi Chen et al.*    | [üìú Paper](https://openaccess.thecvf.com//content/CVPR2023/papers/Chen_Learning_From_Unique_Perspectives_User-Aware_Saliency_Modeling_CVPR_2023_paper.pdf) 
|   2023   |      CVPR      | TempSAL - Uncovering Temporal Information for Deep Saliency Prediction | *Bahar Aydemir et al.*    | [üìÑ Paper](https://arxiv.org/abs/2301.02315) / [Code :octocat:](https://github.com/IVRL/Tempsal)
|   2023   |      BMVC      | Clustered Saliency Prediction | *Rezvan Sherkat et al.*    | [üìÑ Paper](https://arxiv.org/abs/2207.02205)
|   2023   |      NeurIPS      | What Do Deep Saliency Models Learn about Visual Attention? | *Shi Chen et al.*    | [üìÑ Paper](https://arxiv.org/abs/2310.09679) / [Code :octocat:](https://github.com/szzexpoi/saliency_analysis)
|   2023   |      NeurIPS      | What Do Deep Saliency Models Learn about Visual Attention? | *Shi Chen et al.*    | [üìÑ Paper](https://arxiv.org/abs/2310.09679) / [Code :octocat:](https://github.com/szzexpoi/saliency_analysis)
|   2018   |      IEEE Transactions on Image Processing      | Predicting Human Eye Fixations via an LSTM-based Saliency Attentive Model | *Marcella Cornia et al.*    | [üìÑ Paper](https://arxiv.org/pdf/1611.09571.pdf) / [Code :octocat:](https://github.com/marcellacornia/sam)
|   2015   |      CVPR      | SALICON: Saliency in Context | *Ming Jiang et al.*    | [üìÑ Paper](https://www-users.cse.umn.edu/~qzhao/publications/pdf/salicon_cvpr15.pdf) / [Project Page](http://salicon.net/)

## Scanpath Prediction
| **Year** | **Conference / Journal** | **Title** | **Authors** | **Links** |
|:--------:|:--------------:|:---------:|:-----------:|:---------:|
|   2023   |      arXiv      | Contrastive Language-Image Pretrained Models are Zero-Shot Human Scanpath Predictors | *Dario Zanca et al.*    | [üìÑ Paper](https://arxiv.org/abs/2305.12380) / [Dataset ‚úÖ](https://github.com/mad-lab-fau/CapMIT1003)
|   2023   |      CVPR      | Gazeformer: Scalable, Effective and Fast Prediction of Goal-Directed Human Attention | *Sounak Mondal et al.*    | [üìÑ Paper](https://arxiv.org/abs/2303.15274) / [Code :octocat:](https://github.com/cvlab-stonybrook/Gazeformer/)
|   2022   |      ECCV      | Target-absent Human Attention | *Zhibo Yang et al.*    | [üìÑ Paper](https://arxiv.org/abs/2207.01166) / [Code ‚úÖ](https://github.com/cvlab-stonybrook/Target-absent-Human-Attention)
|   2021   |      CVPR      | Predicting Human Scanpaths in Visual Question Answering | *Xianyu Chen et al.*    | [üìÑ Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Predicting_Human_Scanpaths_in_Visual_Question_Answering_CVPR_2021_paper.pdf) / [Code  ‚úÖ](https://github.com/chenxy99/Scanpaths)

# Integrating Human Attention in AI Models
## Image and Video Processing
### Visual Recognition
### Graphic Design







