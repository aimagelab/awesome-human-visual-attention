# Human Visual Attention [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)
This repository contains a curated list of research papers and resources focusing on saliency and scanpath prediction, human attention, human visual search.


â— Latest Update: 22 November 2023. Work in progress, new updates coming soon !!! :construction: :construction:

## ğŸ“š Table of Contents
- [Preprints](#preprints)
- [Published Papers](#published-papers)
  - [Saliency Prediction](#saliency-prediction)
  - [Scanpath Prediction](#scanpath-prediction)
- [Datasets](#datasets)


# Preprints
| **Year** | **Conference / Journal** | **Title**                                           | **Authors**          | **Links** |
|:--------:|:--------------:|:----------------------------------------------------|:---------------------|:---------:|
|   2023   |      arXiv      | Contrastive Language-Image Pretrained Models are Zero-Shot Human Scanpath Predictors | *Dario Zanca et al.*    | [ğŸ“„ Paper](https://arxiv.org/abs/2305.12380) / [Dataset âœ…](https://github.com/mad-lab-fau/CapMIT1003) / Code âŒ
|   2023   |      arXiv      | Predicting Human Attention using Computational Attention | Zhibo Yang et al.*    | [ğŸ“„ Paper](https://arxiv.org/abs/2303.09383) / Code âŒ

# Published Papers
## Saliency Prediction
| **Year** | **Conference / Journal** | **Title**                                           | **Authors**          | **Links** |
|:--------:|:--------------:|:----------------------------------------------------|:---------------------|:---------:|
|   2023   |      CVPR      | Learning from Unique Perspectives: User-aware Saliency Modeling | *Shi Chen et al.*    | [ğŸ“„ Paper](https://openaccess.thecvf.com//content/CVPR2023/papers/Chen_Learning_From_Unique_Perspectives_User-Aware_Saliency_Modeling_CVPR_2023_paper.pdf) / Code âŒ 
|   2023   |      CVPR      | TempSAL - Uncovering Temporal Information for Deep Saliency Prediction | *Bahar Aydemir et al.*    | [ğŸ“„ Paper](https://arxiv.org/abs/2301.02315) / [Code âœ…](https://github.com/IVRL/Tempsal)
|   2023   |      BMVC      | Clustered Saliency Prediction | *Rezvan Sherkat et al.*    | [ğŸ“„ Paper](https://arxiv.org/abs/2207.02205) / Code âŒ
|   2023   |      NeurIPS      | What Do Deep Saliency Models Learn about Visual Attention? | *Shi Chen et al.*    | [ğŸ“„ Paper](https://arxiv.org/abs/2310.09679) / [Code âœ…](https://github.com/szzexpoi/saliency_analysis)
|   2023   |      NeurIPS      | What Do Deep Saliency Models Learn about Visual Attention? | *Shi Chen et al.*    | [ğŸ“„ Paper](https://arxiv.org/abs/2310.09679) / [Code âœ…](https://github.com/szzexpoi/saliency_analysis)
|   2018   |      IEEE Transactions on Image Processing      | Predicting Human Eye Fixations via an LSTM-based Saliency Attentive Model | *Marcella Cornia et al.*    | [ğŸ“„ Paper](https://arxiv.org/pdf/1611.09571.pdf) / [Code âœ…](https://github.com/marcellacornia/sam)
|   2015   |      CVPR      | SALICON: Saliency in Context | *Ming Jiang et al.*    | [ğŸ“„ Paper](https://www-users.cse.umn.edu/~qzhao/publications/pdf/salicon_cvpr15.pdf) / [Project Page âœ…](http://salicon.net/)


---

## Scanpath Prediction
| **Year** | **Conference / Journal** | **Title** | **Authors** | **Links** |
|:--------:|:--------------:|:---------:|:-----------:|:---------:|
|   2023   |      CVPR      | Gazeformer: Scalable, Effective and Fast Prediction of Goal-Directed Human Attention | *Sounak Mondal et al.*    | [ğŸ“„ Paper](https://arxiv.org/abs/2303.15274) / [Code âœ…](https://github.com/cvlab-stonybrook/Gazeformer/)
|   2022   |      ECCV      | Target-absent Human Attention | *Zhibo Yang et al.*    | [ğŸ“„ Paper](https://arxiv.org/abs/2207.01166) / [Code âœ…](https://github.com/cvlab-stonybrook/Target-absent-Human-Attention)
|   2021   |      CVPR      | Predicting Human Scanpaths in Visual Question Answering | *Xianyu Chen et al.*    | [ğŸ“„ Paper](https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Predicting_Human_Scanpaths_in_Visual_Question_Answering_CVPR_2021_paper.pdf) / [Code âœ…](https://github.com/chenxy99/Scanpaths)


---

# Datasets


